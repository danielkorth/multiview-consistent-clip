{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import open3d as o3d\n",
    "import torch\n",
    "import numpy as np\n",
    "import open3d as o3d\n",
    "\n",
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "from PIL import Image\n",
    "from transformers import CLIPProcessor, CLIPModel\n",
    "from pathlib import Path\n",
    "\n",
    "from sklearn.metrics.pairwise import cosine_similarity, euclidean_distances"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Capturing Object from different views"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bunny = o3d.io.read_triangle_mesh(\"/root/multiview-robust-clip/data/shapes/bunny.obj\")\n",
    "bunny.compute_vertex_normals()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "bunny = o3d.io.read_triangle_mesh(\"/root/multiview-robust-clip/data/shapes/bunny.obj\")\n",
    "bunny.compute_vertex_normals()\n",
    "\n",
    "angle = 5\n",
    "\n",
    "rot_matrix = np.array([[np.cos(np.radians(angle)), 0, -np.sin(np.radians(angle))],\n",
    "                             [0, 1, 0],\n",
    "                             [np.sin(np.radians(angle)), 0, np.cos(np.radians(angle))]])\n",
    "\n",
    "current_angle = 0  \n",
    "for i in range(360 // angle):\n",
    "    bunny.rotate(rot_matrix)\n",
    "    vis = o3d.visualization.Visualizer()\n",
    "    vis.create_window()\n",
    "    vis.add_geometry(bunny)\n",
    "    vis.update_geometry(bunny)\n",
    "    vis.capture_screen_image(f'cameraparams_{current_angle:03d}.png', do_render=True)\n",
    "\n",
    "    current_angle += angle\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "o3d.visualization.draw_plotly([bunny])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluating CLIP features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = CLIPModel.from_pretrained(\"openai/clip-vit-base-patch32\").to(device)\n",
    "processor = CLIPProcessor.from_pretrained(\"openai/clip-vit-base-patch32\")\n",
    "device = torch.device('cuda')\n",
    "\n",
    "image_path = Path(\"/root/multiview-robust-clip/data/renderings\")\n",
    "\n",
    "images = [Image.open(x) for x in sorted(image_path.iterdir())]\n",
    "\n",
    "inputs = processor(text=[\"a photo of the stanford bunny\"], images=images, return_tensors=\"pt\", padding=False).to(device)\n",
    "\n",
    "outputs = model(**inputs)\n",
    "logits_per_image = outputs.logits_per_image  # this is the image-text similarity score\n",
    "probs = logits_per_image.softmax(dim=1)  # we can take the softmax to get the label probabilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_embeds = outputs['image_embeds'].detach().cpu().numpy()\n",
    "cosine_similarities = cosine_similarity(image_embeds, image_embeds)\n",
    "euclidean_distances = euclidean_distances(image_embeds, image_embeds)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CALCULATE SIMILARITIES\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.figure(figsize=(12, 6))\n",
    "\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.imshow(cosine_similarities, cmap='hot', interpolation='nearest')\n",
    "plt.colorbar()\n",
    "plt.title('Cosine Similarity')\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.imshow(euclidean_distances, cmap='hot', interpolation='nearest')\n",
    "plt.colorbar()\n",
    "plt.title('Euclidean Distance')\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MAKE VIDEO OF THE 360 DEGREE ROTATION\n",
    "\n",
    "# Define the codec and create VideoWriter object\n",
    "fourcc = cv2.VideoWriter_fourcc(*'mp4v')\n",
    "out = cv2.VideoWriter('output.mp4', fourcc, 20.0, (1920, 1080))\n",
    "\n",
    "\n",
    "# Load images and write to video\n",
    "for image in images:\n",
    "    image_np = np.array(image)\n",
    "    out.write(cv2.cvtColor(image_np, cv2.COLOR_RGB2BGR))\n",
    "\n",
    "# Release the VideoWriter object\n",
    "out.release()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mvr-clip",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
