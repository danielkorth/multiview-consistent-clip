{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import open3d as o3d\n",
    "import torch\n",
    "import numpy as np\n",
    "import open3d as o3d\n",
    "from pathlib import Path\n",
    "\n",
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "from PIL import Image\n",
    "from transformers import CLIPProcessor, CLIPModel\n",
    "from pathlib import Path\n",
    "\n",
    "from sklearn.metrics.pairwise import cosine_similarity, euclidean_distances"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Capturing Object from different views"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bunny = o3d.io.read_triangle_mesh(\"/root/multiview-robust-clip/data/shapes/bunny.obj\")\n",
    "bunny.compute_vertex_normals()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "bunny = o3d.io.read_triangle_mesh(\"/root/multiview-robust-clip/data/shapes/bunny.obj\")\n",
    "bunny.compute_vertex_normals()\n",
    "\n",
    "angle = 5\n",
    "\n",
    "rot_matrix = np.array([[np.cos(np.radians(angle)), 0, -np.sin(np.radians(angle))],\n",
    "                             [0, 1, 0],\n",
    "                             [np.sin(np.radians(angle)), 0, np.cos(np.radians(angle))]])\n",
    "\n",
    "current_angle = 0  \n",
    "for i in range(360 // angle):\n",
    "    bunny.rotate(rot_matrix)\n",
    "    vis = o3d.visualization.Visualizer()\n",
    "    vis.create_window()\n",
    "    vis.add_geometry(bunny)\n",
    "    vis.update_geometry(bunny)\n",
    "    vis.capture_screen_image(f'cameraparams_{current_angle:03d}.png', do_render=True)\n",
    "\n",
    "    current_angle += angle\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "o3d.visualization.draw_plotly([bunny])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluating CLIP features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = CLIPModel.from_pretrained(\"openai/clip-vit-base-patch32\").to(device)\n",
    "processor = CLIPProcessor.from_pretrained(\"openai/clip-vit-base-patch32\")\n",
    "device = torch.device('cuda')\n",
    "\n",
    "image_path = Path(\"/root/multiview-robust-clip/data/renderings\")\n",
    "\n",
    "images = [Image.open(x) for x in sorted(image_path.iterdir())]\n",
    "\n",
    "inputs = processor(text=[\"a photo of the stanford bunny\"], images=images, return_tensors=\"pt\", padding=False).to(device)\n",
    "\n",
    "outputs = model(**inputs)\n",
    "logits_per_image = outputs.logits_per_image  # this is the image-text similarity score\n",
    "probs = logits_per_image.softmax(dim=1)  # we can take the softmax to get the label probabilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_embeds = outputs['image_embeds'].detach().cpu().numpy()\n",
    "cosine_similarities = cosine_similarity(image_embeds, image_embeds)\n",
    "euclidean_distances = euclidean_distances(image_embeds, image_embeds)\n",
    "# CALCULATE SIMILARITIES\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.figure(figsize=(12, 6))\n",
    "\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.imshow(cosine_similarities, cmap='hot', interpolation='nearest')\n",
    "plt.colorbar()\n",
    "plt.title('Cosine Similarity')\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.imshow(euclidean_distances, cmap='hot', interpolation='nearest')\n",
    "plt.colorbar()\n",
    "plt.title('Euclidean Distance')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MAKE VIDEO OF THE 360 DEGREE ROTATION\n",
    "\n",
    "# Define the codec and create VideoWriter object\n",
    "fourcc = cv2.VideoWriter_fourcc(*'mp4v')\n",
    "out = cv2.VideoWriter('output.mp4', fourcc, 20.0, (1920, 1080))\n",
    "\n",
    "\n",
    "# Load images and write to video\n",
    "for image in images:\n",
    "    image_np = np.array(image)\n",
    "    out.write(cv2.cvtColor(image_np, cv2.COLOR_RGB2BGR))\n",
    "\n",
    "# Release the VideoWriter object\n",
    "out.release()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analyze Objaverse data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "renderings = Path(\"/root/multiview-robust-clip/data/objaverse/renderings\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchmetrics.functional.pairwise import pairwise_cosine_similarity\n",
    "\n",
    "cossim_list = list()\n",
    "for shape in renderings.iterdir():\n",
    "    embeddings = list()\n",
    "    for pt in sorted(shape.glob(\"*.pt\")):\n",
    "        embeddings.append(torch.load(pt))\n",
    "    embeddings = torch.stack(embeddings)\n",
    "    simm = pairwise_cosine_similarity(embeddings)\n",
    "    cossim_list.append(simm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_sim = torch.stack(cossim_list)\n",
    "mean_sim = all_sim.mean(dim=0)\n",
    "std_sim = all_sim.std(dim=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "plt.figure(figsize=(12, 6))\n",
    "\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.imshow(mean_sim, cmap='hot', interpolation='nearest')\n",
    "plt.colorbar()\n",
    "plt.title('Mean CosSim')\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.imshow(std_sim, cmap='hot', interpolation='nearest')\n",
    "plt.colorbar()\n",
    "plt.title('STD CosSim')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "plt.figure(figsize=(12, 6))\n",
    "\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.imshow(mean_sim[:36, :36], cmap='hot', interpolation='nearest')\n",
    "plt.colorbar()\n",
    "plt.title('Mean CosSim')\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.imshow(std_sim[:36, :36], cmap='hot', interpolation='nearest')\n",
    "plt.colorbar()\n",
    "plt.title('STD CosSim')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda')\n",
    "model = CLIPModel.from_pretrained(\"openai/clip-vit-base-patch32\").to(device)\n",
    "processor = CLIPProcessor.from_pretrained(\"openai/clip-vit-base-patch32\")\n",
    "\n",
    "sample_image = renderings / \"323851f10fd7483aa803594767ba693a\"\n",
    "\n",
    "images = [Image.open(x) for x in sorted(sample_image.glob(\"*.png\"))]\n",
    "\n",
    "inputs = processor(text=[\"test test 123\"], images=images, return_tensors=\"pt\", padding=False).to(device)\n",
    "\n",
    "outputs = model(**inputs)\n",
    "logits_per_image = outputs.logits_per_image  # this is the image-text similarity score\n",
    "probs = logits_per_image.softmax(dim=1)  # we can take the softmax to get the label probabilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_embeds = outputs['image_embeds'].detach().cpu().numpy()\n",
    "cosine_similarities = pairwise_cosine_similarity(image_embeds)\n",
    "euc_dist = euclidean_distances(image_embeds, image_embeds)\n",
    "# CALCULATE SIMILARITIES\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.figure(figsize=(12, 6))\n",
    "\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.imshow(cosine_similarities, cmap='hot', interpolation='nearest')\n",
    "plt.colorbar()\n",
    "plt.title('Cosine Similarity')\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.imshow(euc_dist, cmap='hot', interpolation='nearest')\n",
    "plt.colorbar()\n",
    "plt.title('Euclidean Distance')\n",
    "\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mvr-clip",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
